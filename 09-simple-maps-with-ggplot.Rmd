# Week 7: Making Simple Maps with R {#map-making-in-R} 

## Intro {#map-making-intro}

For a long time, R has had a relatively simple mechanism, via the `maps` package, for making simple outlines
of maps and plotting lat-long points and paths on them.

More recently, with the advent of packages like `sp`, `rgdal`, and `rgeos`, R has been acquiring much of the
functionality of traditional GIS packages (like ArcGIS, etc).  This is an exciting development, and is now
more easily accessible for the beginner than it was a few years ago when
it required installation of specialized external libraries.  Today, all the necessary libraries get downloaded
when you install the needed packages from CRAN!  

More recently, a third approach to convenient mapping, using `ggmap` has been developed that allows the tiling of 
detailed base maps from Google Earth or Open Street Maps, etc., upon which spatial data may be plotted.


Today, we are going to focus on mapping using base maps from R's tried and true `maps` package and also using the
`ggmap` package.  Next week we will cover some more advanced GIS-related topics using `rgdal`, or `sp` to plot
maps with different projections, etc. 

As in our previous explorations in this course, when it comes to plotting, we are going to completely
skip over R's base graphics system and head directly to Hadley Wickham's `ggplot2` package.  Hadley has
included a few functions that make it relatively easy to interact with the data in R's `maps` package, and
of course, once a map layer is laid down, you have all the power of ggplot at your fingertips to overlay
whatever you may want to over the map.  

`ggmap` is a package that goes out to different map servers and
grabs base maps to plot things on, then it sets up the coordinate system and writes it out as the base layer
for further ggplotting.  It is pretty sweet, but does _not_ support different projections.

### Today's Goals

1. Introduce readers to the map outlines available in the `maps` package
    + Show how to convert those data into data frames that `ggplot2` can deal with
    + Discuss some `ggplot2` related issues about plotting things.
2. Use `ggmap` to make some pretty decent looking maps

I feel that the above two topics should cover a large part of what people will need for making
useful maps of field sites, or sampling locations, or fishing track lines, etc. 

For today we will be skipping how to read in traditional GIS "shapefiles" so as to minimize
the number of packages that need installation, but keep in mind that it isn't too hard to do that
in R, too. (We'll do that next week using the `ggspatial` package).



### Prerequisites
You are going to need to install a few packages beyond the tidyverse.
```{r, eval=FALSE}
# some standard map packages.
install.packages(c("maps", "mapdata"))

# the ggmap package.  Might as well get the bleeding edge version from GitHub
devtools::install_github("dkahle/ggmap")
```




### Load up a few of the libraries we will use

```{r}
library(tidyverse)
library(mapdata)
library(maps)
```


## Plotting maps-package maps with ggplot  {#maps-package-and-ggplot}

### The main players:

* The `maps` package contains a lot of outlines of continents, countries, states, and counties that have
been with R for a long time.  
* The `mapdata` package contains a few more, higher-resolution outlines.
* The `maps` package comes with a plotting function, but, we will opt to use `ggplot2` to plot the 
maps in the `maps` package.  
* Recall that `ggplot2` operates on data frames.  Therefore we need some way to
translate the `maps` data into a data frame format the `ggplot` can use.  This is done
for us with the lovely `map_data` function in ``ggplot2`.

### Maps in the maps package

* Package `maps` provides lots of different map outlines and points for cities, etc.  
* Some examples: `usa`, `nz`, `state`, `world`, etc.  Do `help(package = "maps")` to see
more information.



### Makin' data frames from map outlines

* `ggplot2` provides the `map_data()` function.
    + Think of it as a function that turns a series of points along an outline into a data frame
    of those points.
    + Syntax:  `map_data("name")` where "name" is a quoted string of the name of a map in the `maps` or `mapdata`
    package
* Here we get a USA map from `maps`:
    ```{r}
    usa <- map_data("usa")

    dim(usa)
    
    head(usa)
    
    tail(usa)
    ```
* Here is the high-res world map centered on the Pacific Ocean from `mapdata`
    ```{r}
    w2hr <- map_data("world2Hires")

    dim(w2hr)

    head(w2hr)

    tail(w2hr)
    ```

### The structure of those data frames
These are pretty straightforward:

* `long` is longitude.  Things to the west of the prime meridian are negative, down to -180, and things to the
east of the prime meridian run from 0 to positive 180.
* `lat` is latitude.
* `order`. This just shows in which order `ggplot` should "connect the dots"
* `region` and `subregion` tell what region or subregion a set of points surrounds.
* `group`.  This is _very important_!  `ggplot2`'s functions can take a group argument which 
controls (amongst other things) whether adjacent points should be connected by lines.  If they are
in the same group, then they get connected, but if they are in different groups then they don't.
    + Essentially, having two points in different groups means that `ggplot` "lifts the pen" when going between
    them.
    

### Plot the USA map

* Maps in this format can be plotted with the polygon geom.  i.e. using `geom_polygon()`.
* `geom_polygon()` drawn lines between points and "closes them up" (i.e. draws a line from the last
point back to the first point)
* You have to map the `group` aesthetic to the `group` column
* Of course, `x = long` and `y = lat` are the other aesthetics.

#### Simple black map
By default, `geom_polygon()` draws with no line color, but with a black fill:
```{r}
usa <- map_data("usa") # we already did this, but we can do it again
ggplot() + 
  geom_polygon(data = usa, aes(x = long, y = lat, group = group)) + 
  coord_quickmap()
```

#### What is this coord_quickmap()?

* This is very important when drawing maps.
* It sets the relationship between one unit in the $y$ direction and one unit in the $x$ direction so 
that the _aspect ratio_ is good for your map.
* Then, even if you change the outer dimensions of the plot (i.e. by changing the window size or the size
of the pdf file you are saving it to (in `ggsave` for example)), the aspect ratio remains unchanged.

    
#### Mess with line and fill colors

* Here is no fill, with a red line.  Remember, fixed values of aesthetics (i.e., those that are not
being mapped to a variable in the data frame) go _outside_ the `aes` function.
    ```{r}
    ggplot() + 
      geom_polygon(data = usa, aes(x = long, y = lat, group = group), fill = NA, color = "red") + 
      coord_quickmap()
    ```
    
* Here is violet fill, with a blue line.
    ```{r}
    gg1 <- ggplot() + 
      geom_polygon(data = usa, aes(x = long, y = lat, group = group), fill = "violet", color = "blue") + 
      coord_quickmap()
    gg1
    ```
    
#### Adding points to the map

* Let's add black and yellow points at the NMFS lab in Santa Cruz and at the Northwest Fisheries
Science Center lab in Seattle.
    ```{r}
    labs <- tibble(
      long = c(-122.064873, -122.306417),
      lat = c(36.951968, 47.644855),
      names = c("SWFSC-FED", "NWFSC"))  

    gg1 + 
      geom_point(data = labs, aes(x = long, y = lat), shape = 21, color = "black", fill = "yellow", size = 5) +
      geom_text(data = labs, aes(x = long, y = lat, label = names), hjust = 0, nudge_x = 1)
    ```

#### See how important the group aesthetic is

Here we plot that map without using the group aesthetic:
```{r}
ggplot() + 
      geom_polygon(data = usa, aes(x = long, y = lat), fill = "violet", color = "blue") + 
      geom_point(data = labs, aes(x = long, y = lat), shape = 21, color = "black", fill = "yellow", size = 5) +
      geom_text(data = labs, aes(x = long, y = lat, label = names), hjust = 0, nudge_x = 1) +
      coord_quickmap()
```

That is no bueno!  The lines are connecting points that should not be connected!








### State maps
We can also get a data frame of polygons that tell us above state boundaries:
```{r}
states <- map_data("state")
dim(states)

head(states)

tail(states)
```

#### Plot all the states, all colored a little differently

This is just like it is above, but (using the `aes` function) we can map
the  `fill` aesthetic to `region` and 
make sure the the lines of state borders are white.
```{r}
ggplot(data = states) + 
  geom_polygon(aes(x = long, y = lat, fill = region, group = group), color = "white") + 
  coord_quickmap() +
  guides(fill = FALSE)  # do this to leave off the color legend
```

Boom! That is easy.

#### Plot just a subset of states in the contiguous 48:

* Because the `map_data()` sends back a data frame, we can use the 
tidy tools of `dplyr` to retain just certain parts of it.
* For example, we can grab just CA, OR, and WA and then plot them:
    ```{r}
    west_coast <- states %>%
      filter(region %in% c("california", "oregon", "washington"))
    
    ggplot(data = west_coast) + 
      geom_polygon(aes(x = long, y = lat), fill = "palegreen", color = "black") 
    ```

#### Man that is ugly!! 

* I am just keeping people on their toes. What have we forgotten here?
    + `group`
    + `coord_quickmap()`
* Let's put those back in there:
    ```{r}
    ggplot(data = west_coast) + 
      geom_polygon(aes(x = long, y = lat, group = group), fill = "palegreen", color = "black") + 
      coord_quickmap()
    ```

Phew! That is a little better!


#### Zoom in on California and look at counties

* Getting the california data is easy:
    ```{r}
    ca_df <- states %>%
      filter(region == "california")

    head(ca_df)
    ```

* Now, let's also get the county lines there
    ```{r}
    counties <- map_data("county")
    ca_county <- counties %>%
      filter(region == "california")

    head(ca_county)
    ```

* Plot the state first but let's ditch the axes gridlines, and gray background by
using the super-wonderful `theme_void()` which leaves off everything except the geoms, and the
guides if they are needed.
    ```{r}
    ca_base <- ggplot(data = ca_df, mapping = aes(x = long, y = lat, group = group)) + 
      coord_quickmap() + 
      geom_polygon(color = "black", fill = "gray")
    ca_base + theme_void()
    ```

* Now plot the county boundaries in white:
    ```{r}
    ca_base + theme_void() + 
      geom_polygon(data = ca_county, fill = NA, color = "white") +
      geom_polygon(color = "black", fill = NA)  # get the state border back on top
    ```

#### Get some facts about the counties

* The above is pretty cool, but it seems like it would be a lot cooler if we could plot some information about
those counties.  
* Now I can go to wikipedia or http://www.california-demographics.com/counties_by_population
and grab population and area data for each county.
* In fact, I copied their little table on Wikipedia and saved it into `inputs/ca-counties-wikipedia.txt`. In
full disclosure I also edited the name of San Francisco from "City and County of San Francisco" to 
"San Francisco County" to be like the others (and not break my regular expression searches)
* 2016 Edit!  I had originally pumped the matrix resulting from the `str_match` below through a few
other `stringr` function (like `str_replace_all`) which, apparently, in an older version of `stringr` 
maintained the matrix form, but in a newer version, squashed everything into a vector.  This was kindly
noted by hueykwik [in this issue](https://github.com/eriqande/rep-res-course/issues/74).  So the code below
is modified from what it used to be, but seems to work now.  Just as an aside, in the years since I put this
course together, things have changed quite a bit in the data analysis world, and, as we are doing in this
course in 2017, we are
spending almost all our time in the [tidyverse](http://r4ds.had.co.nz/).
* Watch this regex fun:
```{r, warning=FALSE, message=FALSE}
    library(stringr)
    library(dplyr)

    # make a data frame
    x <- readLines("inputs/ca-counties-wikipedia.txt")
    pop_and_area <- str_match(x, "^([a-zA-Z ]+)County\t.*\t([0-9,]{2,10})\t([0-9,]{2,10}) sq mi$")[, -1] %>%
      na.omit() %>%
      as.data.frame(stringsAsFactors = FALSE) %>%
      mutate(subregion = str_trim(V1) %>% tolower(),
             population = as.numeric(str_replace_all(V2, ",", "")),
             area = as.numeric(str_replace_all(V3, ",", ""))
      ) %>%
      select(subregion, population, area) %>%
      tbl_df()
    
    head(pop_and_area)
    ```
* We now have the numbers that we want, but we need to attach those to 
every point on polygons of the counties.  This is, of course, a job for `left_join` from
the `dplyr` package, and while we are at it, we will add a column of `people_per_mile`
    ```{r}
    cacopa <- left_join(ca_county, pop_and_area, by = "subregion") %>%
      mutate(people_per_mile = population / area)
    head(cacopa)
    ```

#### Now plot population density by county

If you were needing a little more elbow room in the great Golden State, this shows you where you can find it:
```{r}

elbow_room1 <- ca_base + 
      geom_polygon(data = cacopa, aes(fill = people_per_mile), color = "white") +
      geom_polygon(color = "black", fill = NA) +
      theme_void()

elbow_room1 
```




#### Lame!

* The popuation density in San Francisco is so great that it makes it hard to discern differences between
other areas.
* This is a job for a scale transformation.  Let's take the log-base-10 of the population density.
* Instead of making a new column which is log10 of the `people_per_mile` we can just apply the
transformation in the gradient using the `trans` argument
```{r}
elbow_room1 + scale_fill_gradient(trans = "log10")
```

 
#### Still not great
I personally like more color than `ggplot` uses in its default gradient.  In that respect I gravitate more 
toward Matlab's default color gradient.  Can we do something similar with `ggplot`?  (It turns out we can...my apologies
to those purists who would tell me that rainbow colors are not good for showing quantitative scales---I think that in some cases they work reasonaly well...for example the following...of course, there are times
when they work abysmally, as well.)
```{r}
eb2 <- elbow_room1 + 
    scale_fill_gradientn(colours = rev(rainbow(7)),
                         breaks = c(2, 4, 10, 100, 1000, 10000),
                         trans = "log10")
eb2
```

That is reasonably cool.



### zoom in?
Note that the scale of these maps from package `maps` are not great. We can zoom in to the 
Bay region, and it sort of works scale-wise, but if we wanted to zoom in more, it would
be tough.  

Let's try!
```{r}
eb2 + xlim(-123, -121.0) + ylim(36, 38)
```

* Whoa! That is an epic fail. Why?
* Recall that `geom_polygon()` connects the end point of a `group` to its starting point.
* And the kicker: the `xlim` and `ylim` functions in `ggplot2` discard all the data that is
not within the plot area.  
    + Hence there are new starting points and ending points for some groups (or in this case the
    black-line permiter of California) and those points get connected.  Not good.


### True zoom.

* If you want to keep all the data the same but just zoom in, you can use the `xlim` and `ylim` arguments to `coord_cartesian()`.  Though, to keep the aspect ratio correct we must use `coord_quickmap()` instead of 
`coord_cartesian()`.
* This chops stuff off but doesn't discard it from the data set:
    ```{r}
    eb2 + coord_quickmap(xlim = c(-123, -121.0),  ylim = c(36, 38))
    ```

Side Note:  The coastline in the `maps` package is pretty low-resolution, 
and looks like a heap of bird droppings when you zoom way in on it.

If you want to get much more accurate coastlines, you can use better data 
sources like NOAA's [GSHHS](https://www.ngdc.noaa.gov/mgg/shorelines/gshhs.html): A Global 
Self-consistent, Hierarchical, High-resolution Geography Database.  I have a blog post about that
at [http://eriqande.github.io/2014/12/17/compare-map-resolutions.html](http://eriqande.github.io/2014/12/17/compare-map-resolutions.html).

## ggmap {#ggmap-hooray}

The `ggmap` package is a nice way to make quick maps with decent backgrounds!  We will
talk next week about how to get 
better-looking maps at some resolutions by using shapefiles and rasters from [naturalearthdata.com](naturalearthdata.com)
but `ggmap` will get you 95% of the way there with a lot less of the work!

If you don't have it, get the most updated version off GitHub:
```{r, eval=FALSE}
devtools::install_github("dkahle/ggmap")
```
And load it like so:
```{r}
library(ggmap)
```
Note, if you use it in a paper, please cite it:
```{r}
citation("ggmap")
```

### Three examples

* I am going to run through three examples.  Working from the small spatial scale up to a larger spatial scale.
    1. Named "sampling" points on the Sisquoc River from the "Sisquoctober Adventure"
    2. A GPS track from a short bike ride in Wilder Ranch.
    3. Fish sampling locations from the coded wire tag data base.
    
### How ggmap works

* ggmap simplifies the process of downloading base maps from Google or Open Street Maps or Stamen Maps
to use in the background of your plots.
* It also sets the axis scales, etc, in a nice way.  
* Once you have gotten your maps, you make a call with `ggmap()` much as you would with `ggplot()`
* Let's do by example.

### Sisquoctober

* Here is a small data frame of points from the Sisquoc River.
    ```{r}
    sisquoc <- read.table("inputs/sisquoc-points.txt", sep = "\t", header = TRUE)
    sisquoc

    # note that ggmap tends to use "lon" instead of "long" for longitude.
    ```

You can grab Google map tiles by specifying a center and a zoom value that can
be between 3 and 20 inclusive.  Google map tiles are always squarish tiles.  A zoom level of
3 is "world scale", while a zoom value of 20 is "house scale."  Our points in the Sisquoc are
at a neighborhood scale, so we will try `zoom = 15`.  Truth be told it takes some fiddling to get
the zoom right.  

#### Google's "Terrain-map" style

This is a nice choice for natural areas where you want to see some topography:
```{r, cache=TRUE}

get_googlemap(center = c(mean(sisquoc$lon), mean(sisquoc$lat)), zoom = 15) %>%
  ggmap() +
  geom_point(data = sisquoc, mapping = aes(x = lon, y = lat), color = "red") +
  geom_text(data = sisquoc, aes(label = name), angle = 60, hjust = 0, 
            color = "yellow", nudge_x = .0001, nudge_y = .0004, size = 4.5)
```

#### Google's "Satellite" maptype

This can be nice too...
```{r, cache=TRUE}
get_googlemap(center = c(mean(sisquoc$lon), mean(sisquoc$lat)), 
              zoom = 15,
              maptype = "satellite") %>%
  ggmap() +
  geom_point(data = sisquoc, mapping = aes(x = lon, y = lat), color = "red") +
  geom_text(data = sisquoc, aes(label = name), angle = 60, hjust = 0, 
            color = "yellow", nudge_x = .0001, nudge_y = .0004, size = 4.5)

```

### Big Creek in Big Sur

I have been involved in some work at Big Creek, and would like to replace one of our
maps with something better.  So, 
out of curiosity, let's see what Big Creek looks like with Google Maps
```{r, cache=TRUE}
get_googlemap(center = c(-121.595, 36.075), zoom = 15, maptype = "terrain") %>%
  ggmap() 
```
Hmm...that is quite nice.

#### Stamen maps
Can we get the stamen maps to work? Yes, but, for field sites and such, they don't seem
nearly as useful as Google Maps.  Here is some code but we don't bother running it
because it looks really bad anyway.
```{r, eval=FALSE}
bounds <- c(left = -119.77, 
            bottom = 34.750,
            right = -119.73,
            top = 34.755)

# note, if you get these in the wrong order you get a totally 
# uninformative error message.

sisquoc_stamen <- get_stamenmap(bbox = bounds, maptype = "terrain", zoom = 16)

# this looks like crap!

# maybe at bigger zoom levels it would be OK.
```


### How about a bike ride?

* I was riding my bike one day with a my phone and downloaded the GPS readings at short intervals.
* We can plot the route like this:
    ```{r, cache=TRUE}
    bike <- read.csv("inputs/bike-ride.csv")
    head(bike)


    bikemap1 <- get_googlemap(center = c(-122.080954, 36.971709), zoom = 14, maptype = "hybrid")
    ggmap(bikemap1) + 
      geom_path(data = bike, aes(colour = elevation), size = 3, lineend = "round") + 
      scale_color_gradientn(colours = rainbow(7), breaks = seq(25, 200, by = 25))
    ```
* See how we have mapped elevation to the color of the path using our
rainbow colors again.
* Note that getting the right zoom and position for the map is sort of trial and
error.  You can go to google maps to figure out where the center should be: double
click a location to get the lat-long of any spot.
* There is a `make_bbox` function that is supposed to expedite figuring out the zoom, but it 
has never really worked well for me with Google maps at large zooms.  We will see it in action,
below, however.


### Fish sampling locations

For this, I have whittled down some stuff in the coded wire tag data base to georeferenced marine locations in
British Columbia where at least one Chinook salmon was recovered between 2000 and 2012 inclusive.  To see how
I did all that you can check out [this](https://github.com/eriqande/pbt-feasibility/blob/4ea2fc960f74f66b5ec3a11c107cdc52bfb346dc/Rmd/02-02-explore-recovery-and-catch-sample-data.Rmd#looking-at-locations-of-location-codes)

Let's have a look at the data:
```{r}
bc <- readRDS("inputs/bc_sites.rds")

# look at some of it:
bc %>% 
  select(state_or_province:sub_location, longitude, latitude)
```

So, we have 1,113 points to play with.  

#### What do we hope to learn?

* These locations in BC are hierarchically structured.  I am basically interested in how close together
sites in the same "region" or "area" or "sector" are, and pondering whether it is OK to aggregate
fish recoveries at a certain level for the purposes of getting a better overall estimate of the proportion
of fish from different hatcheries in these areas.

* So, pretty simple stuff.  I just want to plot these points on a map, and paint them a different
color according to their sector, region, area, etc.
* Let's just enumerate things first, using `dplyr`:
    ```{r}
    bc %>% 
      count(sector, region, area)
    
    bc %>%
      count(sector, region)
    ```
* That looks good.  It appears like we could probably color code over the whole area down to region, and
then down to area within subregions.

#### Makin' a map.

* Let us try to use `make_bbox()` to see if it will work better when used on a large scale.
Note: in order to use an approximate bounding box, we have to use `get_map()` rather than
`get_googlemap()`. Doing so looks like this...
```{r, cache=TRUE}
# compute the bounding box
bc_bbox <- make_bbox(lat = latitude, lon = longitude, data = bc)
bc_bbox

# grab the maps from google
bc_big <- get_map(location = bc_bbox, maptype = "terrain", source = "google")

# plot the points and color them by sector
ggmap(bc_big) + 
  geom_point(data = bc, mapping = aes(x = longitude, y = latitude, color = sector))
```

* Cool! That was about as easy as could be.  North is in the north, south is in the south, and 
the three reddish points are clearly aberrant ones at the mouths of rivers.


#### Coloring it by region

* We should be able to color these all by region to some extent (it might get overwhelming), but let
us have a go with it.
* Notice that region names are unique overall (not just within N or S) so we can just color by region name.
```{r}
ggmap(bc_big) + 
  geom_point(data = bc, mapping = aes(x = longitude, y = latitude, color = region))
```

* Once again that was dirt easy, though at this scale with all the different
regions, it is hard to resolve all the colors. In general, it gets hard to resolve more than 7 or 8 
colors on a map.  


## In-class review and short assignment

A lot of stuff went by in the last few sections.  Here are the key players, in review:

Using the `maps` package with `ggplot2`:

- `library(maps)` this loads the library that has the map data.
- `map_data()` this function from `ggplot2` grabs map data from the `maps` package and returns
it as a data frame `ggplot` can handle.  Choices for the arguments are many.  Some common ones are
`"states"`, `"counties"`, `"usa"`, etc.
- `geom_polygon()` plots boundaries from the maps package.
- Don't forget: `group = group` in the aesthetics!
- `coord_quickmap()` ggplot function to get a good aspect ratio (or do projections, if you want...)
- Zoom in without improper chopping with `coord_quickmap(xlim = ..., ylim = ...)`


Using `ggmap`:

- Get the latest version from GitHub: `devtools::install_github("dkahle/ggmap")`
- `get_googlemap(center = c(long, lat), zoom = 3 to 20)`
- Put the output of `get_googlemap()` into the `ggmap()` function and then proceed as 
you would with ggplot.
- Google Maps maptypes: "terrain", "satellite", "hybrid"

### Short assignment of plotting with `maps`

If you don't have your own data to start plotting, you can try to make the following plot of the 
four "four-corners" states and their capitals.  I have a list of capitals in the course
repository that I read in like this:
```{r}
caps <- read_csv("inputs/state_capitals.csv")
```
It looks like this:
```{r}
caps
```
You can quickly download the CSV file from [here](https://www.dropbox.com/s/d3gehuzl4pdkntj/state_capitals.csv?dl=1).

Once you have that, try to put together a map that looks like this:
```{r, echo=FALSE}
states <- map_data("state") %>%
  as_tibble

fc <- states %>%
  filter(region %in% c("arizona", "utah", "new mexico", "colorado"))

caps_fc <- caps %>%
  filter(state %in% c("Arizona", "Utah", "New Mexico", "Colorado"))

ggplot() +
  geom_polygon(data = fc, mapping = aes(x = long, y = lat, fill = region), colour = "white") +
  coord_quickmap() +
  geom_point(data = caps_fc, mapping = aes(x = long, y = lat), shape = 23, fill = "yellow", colour = "black", size = 3) +
  geom_text(data = caps_fc, mapping = aes(x = long, y = lat, label = capital), 
            hjust = 0, nudge_x = 0.3) +
  scale_fill_manual(values = c("red", "green", "brown", "blue"))
```

OK, now, to display your mad dplyr skills and mapping capabilities, do the gyrations 
necessary to do this:
```{r, echo=FALSE}
s2 <- states %>%
  mutate(state = ifelse(region %in% c("arizona", "utah", "new mexico", "colorado"), region, "not-a-4-corner-state"))

ggplot() +
  geom_polygon(data = s2, mapping = aes(x = long, y = lat, fill = state, group = group), colour = "white") +
  coord_quickmap(xlim = c(-125, -95), ylim = c(30, 50)) +
  geom_point(data = caps, mapping = aes(x = long, y = lat), shape = 23, fill = "yellow", colour = "black", size = 3) +
  geom_text(data = caps, mapping = aes(x = long, y = lat, label = capital), 
            hjust = 0, nudge_x = 0.3) +
  scale_fill_manual(values = c("red", "green", "brown", "gray", "blue")) +
  theme_bw()
```


### Short assignment of plotting with ggmap()

Here are the locations of 357 Wilson's warblers sampled in North America.  You can
download them from [here](https://www.dropbox.com/s/fiq6zj0qsmj0dqa/breeding_wiwa_isotopes.rds?dl=1).
```{r}
wiwa <- readRDS("inputs/breeding_wiwa_isotopes.rds")

# look at the range of the lat longs
range(wiwa$lat)
range(wiwa$long)
```

The data frame looks like this:
```{r}
wiwa
```
Let's make a google_map with some of that info on it---namely the locations of the 
samples colored by the State or Province that they are in.
```{r, echo=FALSE}
get_googlemap(center = c(-110, 49), zoom = 3, maptype = "hybrid") %>%
  ggmap() +
  geom_jitter(data = wiwa, mapping = aes(x = long, y = lat, colour = State))
```

That shows one of the limitations of plotting things in unprojected latitude and longitude coordinates:
Alaska gets all inflated.  Next week, if everyone really wants to see how we might overcome
that using the Natural Earth Data rasters, we might just be able to do so.



